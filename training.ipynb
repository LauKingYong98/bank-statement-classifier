{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1d067b-accb-42b4-ba9c-a93c9d44223a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the environment \n",
    "# conda env create -f environment.yml\n",
    "\n",
    "# activate the environment\n",
    "# conda activate mlproject\n",
    "\n",
    "#if you prefer to set up the environment by yourself, you may create Python virtual environment and install the following packages\n",
    "# !pip install pandas numpy torch transformers datasets scikit-learn evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411700b6-991a-4861-a229-194d7abd35fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "import torch\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba74b79-c1c5-4292-a85e-3924c6a666d5",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9ae8b5-3435-445a-a4e8-ab5973c3c86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "df = pd.read_csv('data/training-data.csv')\n",
    "\n",
    "# display first few rows to understand the data structure\n",
    "print(df.head())\n",
    "\n",
    "#check the shape of the loaded_dataset\n",
    "print() #print a blank line\n",
    "print(f\"The shape of rows and columns in this dataset is: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251c876f-58ef-4de7-9180-d5e958669a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the column is properly labelled\n",
    "print(df.columns)\n",
    "\n",
    "# there are blank spaces before and after the column name, we should remove it. we can do so by using strip function\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "print(df.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ac5266-0a3b-4977-b230-bf846919f7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the datatypes\n",
    "print(df.dtypes)\n",
    "\n",
    "print()\n",
    "# check if any missing value in each columns\n",
    "print(df.isnull().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604113d8-6220-4938-91c3-4e88315064b6",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "1. We can perform feature engineering to transform raw data into features/ pattern that are easier to be recognised.\n",
    "2. We do it by doing structured concatenation which we explicitly labelling each data, by doing so hopefully it will help model to easily recognised the pattern on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4284d98f-4a60-4dba-857c-b935200bc71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate relevant columns into a single string per row with explicit labels\n",
    "df['combined_text'] = df.apply(lambda row: f\"Bank: {row['Bank']} Currency: {row['Currency']} Date: {row['Date']} Amount: {row['Amount']} Text: {row['Text']}\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d54b20-ec87-4ce4-926e-6e8fa0841521",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.combined_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d776ff79-d9c9-4d0f-bfad-1da68470ac32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check if the maximum combined length for 1 token exceed the maximum length of a token in the model. \n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert/distilbert-base-uncased')\n",
    "\n",
    "# Tokenize the combined texts and calculate the token lengths\n",
    "token_lengths = df['combined_text'].apply(lambda x: len(tokenizer(x, truncation=False)['input_ids']))\n",
    "\n",
    "# Print the maximum token length\n",
    "max_token_length = token_lengths.max()\n",
    "print(f\"Maximum token length of combined text: {max_token_length}\")\n",
    "\n",
    "# Check if the maximum token length exceeds the model's limit\n",
    "max_model_length = tokenizer.model_max_length\n",
    "print(f\"Model maximum token length: {max_model_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a375e8-b658-4282-9f1a-cf21361e3ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to numerical form\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['Remark'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d4c5d0-3a93-48b6-8f5f-40ac5fe5289a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mapping of original labels to encoded labels\n",
    "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "\n",
    "print(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca6d8f5-3584-4fa8-a722-3985fc2f0247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use HuggingFace Dataset Module for Training as it is better integration with Transfomers Module.\n",
    "# in Dataset module, data are load in dict format\n",
    "# lets perform final check the df dataset after transfom, it should include two additional columns: 'combined_text' & 'label'\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7e5078-7bef-4840-b5ab-b7da4b262dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new df that only stored the columns needed for fine-tune training \n",
    "df_final = df[['combined_text','label']]\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806a0d7b-2641-48f2-bfda-c81dfa2e85bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the processed df as a csv file, unfilter the code to process\n",
    "df_final.to_csv('data/training-data-pd-out.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600ba262-b2cb-4837-87bd-d437464536ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the processed csv file with two column \"input\" & 'label' under dataset library\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"csv\", data_files=\"data/training-data-pd-out.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478bab93-e234-46cb-8752-e8561a6f34f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the dataset \n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f25d87-d317-4a62-bbbe-4092201aa520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep track on the original size of the dataset, it should matched with the total size after split  \n",
    "original_size = dataset[\"train\"].num_rows\n",
    "print(f\"Original_size of dataset: {original_size}\")\n",
    "\n",
    "# split the dataset into training set and testing set with a ratio of 80:20\n",
    "dataset_final = dataset[\"train\"].train_test_split(test_size=0.2, shuffle=True, seed=42)\n",
    "\n",
    "train_size = dataset_final[\"train\"].num_rows\n",
    "test_size = dataset_final[\"test\"].num_rows\n",
    "total_size = train_size + test_size\n",
    "\n",
    "print(\"Training dataset size:\", train_size)\n",
    "print(\"Testing dataset size:\", test_size)\n",
    "print(\"Total size after split:\", total_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba84bc9-2cb3-40cf-b72c-1904766a3041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final check on the dataset_final to see if the columns & row are correct before we perform fine-tune training\n",
    "dataset_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03de4e6-9983-4e50-a3b2-0a1b539618e1",
   "metadata": {},
   "source": [
    "### Fine-tune Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a58c203-c50e-4bed-882e-cd2be4b56a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"distilbert/distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"combined_text\"], truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = dataset_final.map(tokenize_function, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b453fba-8200-4766-8153-80a59cc67001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the dataset after the features are mapped and tokenized into format that the model can read\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fdd6ef-ff3f-45d4-be0d-e524a1e4140e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns that model does not expect\n",
    "tokenized_datasets = tokenized_datasets.remove_columns([\"combined_text\"])\n",
    "\n",
    "# rename the column label to labels as the model expects the argument to be named \"labels\"\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "\n",
    "# Set the format of the datasets so they return PyTorch tensors instead of lists\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "# check the result of the column in train & test\n",
    "print(tokenized_datasets[\"train\"].column_names)\n",
    "print(tokenized_datasets[\"test\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0927f515-d10f-4619-8a6b-6c23651df6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we have loaded the pre-training model, tokenized the dataset. we are good to start the fine-tune training!\n",
    "# from transformers import TrainingArguments, AutoModelForSequenceClassification, Trainer\n",
    "\n",
    "# define training arguments & load the pre-trained model\n",
    "training_args = TrainingArguments(\n",
    "    \"model/test-trainer\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01\n",
    ")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c127b68d-d77b-44f8-8b59-0b031f87d281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import evaluate\n",
    "\n",
    "# define the compute_metrics function\n",
    "def compute_metrics(eval_preds):\n",
    "    metric = evaluate.load(\"accuracy\")\n",
    "    logits, labels = eval_preds\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=preds, references=labels)\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57393355-372a-4908-b91d-9c41f370a3d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fb5cac-d420-494e-84ee-9aa382551588",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1671c827-1819-48b0-862a-9495b1cc7ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are the codes to evaluate the training result (kind of unnecessary because we already include evaluate function when fine tune the model)\n",
    "evaluation_results = trainer.evaluate()\n",
    "print(evaluation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c324c616-4023-4a61-bd55-59bc354d5deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can manually calculate the accuracy too\n",
    "predictions = trainer.predict(tokenized_datasets[\"test\"])\n",
    "print(predictions.predictions.shape, predictions.label_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd2c3f0-55f2-4803-b08f-42191038c3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "preds = np.argmax(predictions.predictions, axis=-1)\n",
    "\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "metric.compute(predictions=preds, references=predictions.label_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96eead7c-26be-4107-9be1-a95101036b65",
   "metadata": {},
   "source": [
    "### Save the fine-tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be18d6d-8aba-4334-8175-b2342e158ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save_pretrained(\"model/bank-classifier-model\")\n",
    "\n",
    "# Save the tokenizer\n",
    "tokenizer.save_pretrained(\"model/bank-classifier-tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ca9659-ae0a-43d6-9adb-0ca155481e0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlproject",
   "language": "python",
   "name": "mlproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
